{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958871f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import obonet\n",
    "import BOCC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from webweb import Web\n",
    "import os\n",
    "import seaborn as sns\n",
    "from BOCC import BOCC, load_clusters\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "import typing\n",
    "import matplotlib.patches as mpatches\n",
    "from upsetplot import from_memberships\n",
    "from upsetplot import plot\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "\n",
    "std_fontsize = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "G19 = nx.read_edgelist('../Edgelists/String_HPO_2019.phenotypic_branch.edgelist.txt')\n",
    "G20 = nx.read_edgelist('../Edgelists/String_HPO_2020.phenotypic_branch.edgelist.txt')\n",
    "G21 = nx.read_edgelist('../Edgelists/String_HPO_2021.phenotypic_branch.edgelist.txt')\n",
    "G22 = nx.read_edgelist('../Edgelists/String_HPO_2022.phenotypic_branch.edgelist.txt')\n",
    "\n",
    "def remove_trivial_coms(coms):\n",
    "    keepers = []\n",
    "    for c in coms:\n",
    "        if len(c.members) > 2 and len(c.get_genes()) > 0 and len(c.get_genes()) != len(c.members):\n",
    "            keepers.append(c)\n",
    "    return keepers\n",
    "\n",
    "g_subcoms = load_clusters('../SubComs/2021/paris.greedy.2021.coms.txt')\n",
    "w_subcoms = load_clusters('../SubComs/2021/paris.walktrap.2021.coms.txt')\n",
    "i_subcoms = load_clusters('../SubComs/2021/paris.infomap.2021.coms.txt')\n",
    "c_subcoms = load_clusters('../SubComs/2021/paris.cesna.2021.coms.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_pairs_from_com(coms,G):\n",
    "    # this function returns a list of all possible pairings of genes and phenotypes in all clusters - regardless of if they exist or not\n",
    "    pairs = []\n",
    "    for com in coms:\n",
    "        pairs.append(set())\n",
    "        genes = [x for x in com.members if 'HP:' not in x]\n",
    "        hpos = [x for x in com.members if 'HP:' in x]\n",
    "#         print('HPOs',len(hpos))\n",
    "#         print('Genes',len(genes))\n",
    "        for g in genes:\n",
    "            for h in hpos:\n",
    "                p=[g,h]\n",
    "                # check if p in in G\n",
    "                if G.has_edge(p[0],p[1]):\n",
    "                    continue\n",
    "                p.sort()\n",
    "                pairs[-1].add(str(p))\n",
    "    return pairs\n",
    "\n",
    "def get_possible_pairs_from_com_non_bocc(com,G):\n",
    "    # this function returns a list of all possible pairings of genes and phenotypes in all clusters - regardless of if they exist or not\n",
    "    pairs = set()\n",
    "    genes = [x for x in com if 'HP:' not in x]\n",
    "    hpos = [x for x in com if 'HP:' in x]\n",
    "#         print('HPOs',len(hpos))\n",
    "#         print('Genes',len(genes))\n",
    "    for g in genes:\n",
    "        for h in hpos:\n",
    "            p=[g,h]\n",
    "            # check if p in in G\n",
    "            if G.has_edge(p[0],p[1]):\n",
    "                continue\n",
    "            p.sort()\n",
    "            pairs.add(str(p))\n",
    "    return pairs\n",
    "\n",
    "def load_new_edges(el,G):\n",
    "    pairs = set()\n",
    "    for line in open(el,'r'):\n",
    "        row = line.strip().split('\\t')\n",
    "        row.sort()\n",
    "        if G.has_edge(row[0],row[1]):\n",
    "            continue\n",
    "        pairs.add(str(row))\n",
    "    return pairs\n",
    "\n",
    "# load new edges but shuffle them\n",
    "def load_new_edges_shuffled(el, seed=None):\n",
    "    pairs = set()\n",
    "    genes = []\n",
    "    hpos = []\n",
    "    rows = 0\n",
    "    for line in open(el,'r'):\n",
    "        row = line.strip().split('\\t')\n",
    "        # add the HPO term to the list of HPO terms\n",
    "        if 'HP:' in row[0]:\n",
    "            hpos.append(row[0])\n",
    "            genes.append(row[1])\n",
    "        else:\n",
    "            genes.append(row[0])\n",
    "            hpos.append(row[1])\n",
    "        rows += 1\n",
    "    # shuffle the genes and hpos\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(genes)\n",
    "    np.random.shuffle(hpos)\n",
    "    # create the pairs\n",
    "    for i in range(len(genes)):\n",
    "        p = [genes[i],hpos[i]]\n",
    "        p.sort()\n",
    "        pairs.add(str(p))\n",
    "    return pairs\n",
    "    \n",
    "\n",
    "def rediscover(pairs, el_pairs):\n",
    "    # find the intersection\n",
    "    results = []\n",
    "    for com_pairs in pairs:\n",
    "        results.append(len(com_pairs.intersection(el_pairs)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd54ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = load_new_edges_shuffled(el='../g2p_Edgelists/String_HPO_2020.phenotypic_branch.g2p_edgelist.txt',seed=0)\n",
    "s1 = load_new_edges_shuffled(el='../g2p_Edgelists/String_HPO_2020.phenotypic_branch.g2p_edgelist.txt',seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3582f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the possible pairs\n",
    "g_pairs = get_possible_pairs_from_com(g_subcoms,G19)\n",
    "print('Greedy',len(g_pairs))\n",
    "\n",
    "# load the new edges\n",
    "el_pairs = load_new_edges(el='../g2p_Edgelists/String_HPO_2020.phenotypic_branch.g2p_edgelist.txt', G=G19)\n",
    "print('2020',len(el_pairs))\n",
    "\n",
    "# score the cluster's rediscoveries\n",
    "rediscoveries = rediscover(g_pairs, el_pairs)\n",
    "print('Greedy',len(rediscoveries))\n",
    "\n",
    "# do 10 shuffled rediscoveries\n",
    "shuffled_rediscoveries = []\n",
    "for i in range(1000):\n",
    "    s = load_new_edges_shuffled(el='../g2p_Edgelists/String_HPO_2020.phenotypic_branch.g2p_edgelist.txt',seed=i)\n",
    "    shuffled_rediscoveries.append(rediscover(g_pairs, s))\n",
    "\n",
    "# compare the rediscoveries to the shuffled rediscoveries\n",
    "p_values = []\n",
    "for i in range(len(rediscoveries)):\n",
    "    print('Cluster',i)\n",
    "    this_coms_shuffled_rediscoveries = [x[i] for x in shuffled_rediscoveries]\n",
    "    # empirical p-value for number of times rediscovery is greater than or equal to the shuffled rediscovery\n",
    "    p = 1 - (sum([1 for x in this_coms_shuffled_rediscoveries if rediscoveries[i] >= x])/len(this_coms_shuffled_rediscoveries))\n",
    "    p_values.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f265f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the p-values\n",
    "plt.hist(p_values,bins=100)\n",
    "plt.xlabel('p-value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Greedy')\n",
    "plt.yscale('log')\n",
    "plt.savefig('Greedy.png',dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa196169",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_scores = {}\n",
    "first= True\n",
    "for line in open('../XGBoost2021ClusterRankings.csv','r'):\n",
    "    if first:\n",
    "        first = False\n",
    "        continue\n",
    "#     print(line)\n",
    "    row = line.strip().split(',')\n",
    "    cluster_scores[row[0]] = 1 - float(row[1])\n",
    "print(list(cluster_scores.keys())[0])\n",
    "\n",
    "sub_com_names = ['paris.greedy.2021:{}'.format(x.name) for x in g_subcoms]\n",
    "print(sub_com_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef389bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub set p valuesa and sub com names to only include those that are in the cluster_scores dictionary\n",
    "p_values_filtered = []\n",
    "sub_com_names_filtered = []\n",
    "for i in range(len(p_values)):\n",
    "    if sub_com_names[i] in cluster_scores:\n",
    "        p_values_filtered.append(p_values[i])\n",
    "        sub_com_names_filtered.append(sub_com_names[i])\n",
    "# make a dataframe of the p-values and cluster scores and cluster names\n",
    "df = pd.DataFrame({'p-value':p_values_filtered,'cluster_score': [cluster_scores[x] for x in sub_com_names_filtered],'cluster_name':sub_com_names_filtered})\n",
    "\n",
    "# plot the p-values vs the cluster scores\n",
    "# plt.scatter(df['cluster_score'],df['p-value'],s=4,alpha=.2)\n",
    "# plt.xlabel('Cluster Score')\n",
    "# plt.ylabel('p-value')\n",
    "# plt.title('Greedy')\n",
    "# plt.savefig('greedy.scatter.png',dpi=300)\n",
    "\n",
    "# make the same scatter plot but plot density on axers above and to the right of it\n",
    "# fig, ax = plt.subplots(2,2)\n",
    "# same as the line above but with width and height ratios\n",
    "fig, ax = plt.subplots(2,2,gridspec_kw={'width_ratios':[3,1],'height_ratios':[1,3]})\n",
    "fig.set_size_inches(10,10)\n",
    "ax[1,0].scatter(df['cluster_score'],df['p-value'],s=4,alpha=.2)\n",
    "ax[0,0].hist(df['cluster_score'],bins=100)\n",
    "ax[1,1].hist(df['p-value'],bins=100,orientation='horizontal')\n",
    "# ax[0,1].set_yscale('log')\n",
    "# ax[1,0].set_xscale('log')\n",
    "ax[1,0].set_xlabel('Cluster Score',fontsize=std_fontsize)\n",
    "ax[1,0].set_ylabel('p-value',fontsize=std_fontsize)\n",
    "ax[0,0].set_ylabel('Count',fontsize=std_fontsize)\n",
    "ax[1,1].set_xlabel('Count',fontsize=std_fontsize)\n",
    "ax[1,1].set_xscale('log')\n",
    "ax[0,1].set_visible(False)\n",
    "# remove top and right spines\n",
    "ax[0,0].spines['top'].set_visible(False)\n",
    "ax[0,0].spines['right'].set_visible(False)\n",
    "ax[1,0].spines['top'].set_visible(False)\n",
    "ax[1,0].spines['right'].set_visible(False)\n",
    "ax[1,1].spines['top'].set_visible(False)\n",
    "ax[1,1].spines['right'].set_visible(False)\n",
    "ax[0,1].spines['top'].set_visible(False)\n",
    "ax[0,1].spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../Figures/greedy.snowball_v_edge_shuffle.scatter.density.png',dpi=300)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9c2bb61",
   "metadata": {},
   "source": [
    "# Random Clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6818ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each cluster, get the number of members\n",
    "random.seed(0)\n",
    "# check if cluster_rediscoveries.pickle exists\n",
    "if os.path.exists('cluster_rediscoveries.pickle'):\n",
    "    # load the pickle file\n",
    "    with open('cluster_rediscoveries.pickle','rb') as f:\n",
    "        cluster_rediscoveries = pickle.load(f)\n",
    "else:\n",
    "    cluster_rediscoveries = []\n",
    "    for j in range(1000):\n",
    "        if j % 100 == 0:\n",
    "            print(j)\n",
    "        cluster_rediscoveries.append([])\n",
    "        for i in range(len(g_subcoms)):\n",
    "            # print('Cluster',i)\n",
    "            first_resample = True\n",
    "            # print(i)\n",
    "            size = len(g_subcoms[i].members)\n",
    "            if size < 3:\n",
    "                cluster_rediscoveries[-1].append(rediscoveries)\n",
    "                continue\n",
    "            # from G19 pick size number of nodes at random, if there nodes do not have a phenotype, then re pick\n",
    "            heterozygous = False\n",
    "            while not heterozygous:\n",
    "                # the line above but make sure it samples without replacement\n",
    "                nodes = random.choices(list(G19.nodes),k=size)\n",
    "                has_hpo = any([ 'HP:' in x for x in nodes])\n",
    "                has_gene = any([ 'HP:' not in x for x in nodes])\n",
    "                heterozygous = has_hpo and has_gene\n",
    "                # if not heterozygous:\n",
    "                #     if first_resample:\n",
    "                #         first_resample = False\n",
    "                    # else:\n",
    "                        # print('re sampling')\n",
    "                        # print(nodes)\n",
    "            random_pairs = get_possible_pairs_from_com_non_bocc(nodes, G19)\n",
    "            rediscoveries = len(random_pairs.intersection(el_pairs))\n",
    "            cluster_rediscoveries[j].append(rediscoveries)\n",
    "\n",
    "    for i in range(len(cluster_rediscoveries)):\n",
    "        print(i, len(cluster_rediscoveries[i]))\n",
    "    with open('cluster_rediscoveries.pickle','wb') as f:\n",
    "        pickle.dump(cluster_rediscoveries,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle cluster_rediscoveries\n",
    "\n",
    "with open('cluster_rediscoveries.pickle','rb') as f:\n",
    "        cluster_rediscoveries = pickle.load(f)\n",
    "# make pvalues of cluster_rediscoveries vs rediscoveries\n",
    "rediscovery_p_values = []\n",
    "for i in range(len(rediscoveries)):\n",
    "    print(i)\n",
    "    this_coms_cluster_rediscoveries = [x[i] for x in cluster_rediscoveries]\n",
    "    # empirical p-value for number of times rediscovery is greater than or equal to the shuffled rediscovery\n",
    "    p = 1 - (sum([1 for x in this_coms_cluster_rediscoveries if rediscoveries[i] >= x])/len(this_coms_cluster_rediscoveries))\n",
    "    rediscovery_p_values.append(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac33d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
